{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where all data is stored\n",
    "base_dir = 'data/data_warehouse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse dates from folder names\n",
    "def parse_date(folder_name):\n",
    "    try:\n",
    "        return datetime.strptime(folder_name, '%Y-%m-%d')\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process player results (daily stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_player_results():\n",
    "    results_files = glob.glob(os.path.join(base_dir, '*', 'player_results.csv'))\n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"Found {len(results_files)} player_results.csv files\")\n",
    "    \n",
    "    for file in results_files:\n",
    "        # Extract date from path\n",
    "        date_str = file.split(os.sep)[-2]\n",
    "        date = parse_date(date_str)\n",
    "        \n",
    "        if date:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                \n",
    "                # Add date information\n",
    "                df['Date'] = date\n",
    "                \n",
    "                # Convert numeric columns if needed\n",
    "                numeric_cols = ['Salary', 'Floor', 'Ceiling', 'FPG', 'FPPM', 'USG', 'FGA', 'MPG', \n",
    "                               'Proj Mins', 'FC Proj', 'My Proj', 'Mins', 'Score', 'Val']\n",
    "                \n",
    "                for col in numeric_cols:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Add to results\n",
    "                all_results.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process contest standings and player selection stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_contest_data():\n",
    "    standings_files = glob.glob(os.path.join(base_dir, '*', '*', 'contest-standings.csv'))\n",
    "    all_entries = []\n",
    "    all_player_records = []\n",
    "    \n",
    "    print(f\"Found {len(standings_files)} contest-standings.csv files\")\n",
    "    \n",
    "    for file in standings_files:\n",
    "        try:\n",
    "            # Extract date and contest name from path\n",
    "            path_parts = file.split(os.sep)\n",
    "            date_str = path_parts[-3]\n",
    "            contest_name = path_parts[-2]\n",
    "            date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "            \n",
    "            # Load the entire CSV\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            \n",
    "            # The 'X' column separates the two tables\n",
    "            # Make sure we get the right column index in case column order varies\n",
    "            x_idx = df.columns.get_loc('X') if 'X' in df.columns else 6\n",
    "            \n",
    "            # Split into two separate tables\n",
    "            entries_df = df.iloc[:, :x_idx].copy()  # Columns to the left of 'X'\n",
    "            players_df = df.iloc[:, x_idx+1:].copy()  # Columns to the right of 'X'\n",
    "            \n",
    "            # Clean entries data - drop rows without entry information\n",
    "            entries_df.dropna(subset=['EntryId'], inplace=True)\n",
    "            entries_df['Date'] = date\n",
    "            entries_df['Contest'] = contest_name\n",
    "            \n",
    "            # Extract contest type\n",
    "            if 'H2H' in contest_name or 'Head-to-Head' in contest_name:\n",
    "                contest_type = 'Head-to-Head'\n",
    "            elif 'Double Up' in contest_name or '50/50' in contest_name:\n",
    "                contest_type = 'Double Up'\n",
    "            elif 'GPP' in contest_name or 'Tournament' in contest_name:\n",
    "                contest_type = 'Tournament'\n",
    "            else:\n",
    "                contest_type = 'Other'\n",
    "                \n",
    "            entries_df['ContestType'] = contest_type\n",
    "            \n",
    "            # Extract entry fee if possible\n",
    "            try:\n",
    "                entry_fee = float(contest_name.split('$')[1].split('entry')[0])\n",
    "                entries_df['EntryFee'] = entry_fee\n",
    "            except:\n",
    "                entries_df['EntryFee'] = None\n",
    "            \n",
    "            # Process player records\n",
    "            # First, drop rows with no player information\n",
    "            players_df.dropna(subset=['Player'], inplace=True)\n",
    "            \n",
    "            # Add identifying information\n",
    "            players_df['Date'] = date\n",
    "            players_df['Contest'] = contest_name\n",
    "            players_df['ContestType'] = contest_type\n",
    "            \n",
    "            # Add these records to our lists\n",
    "            all_entries.append(entries_df)\n",
    "            all_player_records.append(players_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    # Combine all entry data\n",
    "    combined_entries = pd.concat(all_entries, ignore_index=True)\n",
    "    \n",
    "    # Combine all player record data\n",
    "    combined_player_records = pd.concat(all_player_records, ignore_index=True)\n",
    "     \n",
    "    return combined_entries, combined_player_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process player projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_player_projections():\n",
    "    player_files = glob.glob(os.path.join(base_dir, '*', '*', 'players.csv'))\n",
    "    all_players = []\n",
    "    \n",
    "    print(f\"Found {len(player_files)} players.csv files\")\n",
    "    \n",
    "    for file in player_files:\n",
    "        try:\n",
    "            path_parts = file.split(os.sep)\n",
    "            date_str = path_parts[-3]\n",
    "            contest_name = path_parts[-2]\n",
    "            date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "            \n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Parse game info into useful components\n",
    "            if 'GameInfo' in df.columns:\n",
    "                # Example format: \"MIL@CHI 01/28/2021\"\n",
    "                df['HomeTeam'] = df['GameInfo'].str.split('@').str[1].str.split(' ').str[0]\n",
    "                df['AwayTeam'] = df['GameInfo'].str.split('@').str[0]\n",
    "                df['IsHome'] = df['Team'] == df['HomeTeam']\n",
    "            \n",
    "            # Convert numeric columns\n",
    "            numeric_cols = ['Salary', 'AvgPointsPerGame', 'Projection', 'Projection_dfn', 'Actual_fpts']\n",
    "            for col in numeric_cols:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Add metadata\n",
    "            df['Date'] = date\n",
    "            df['Contest'] = contest_name\n",
    "            \n",
    "            all_players.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    # Combine all player data\n",
    "    combined_players = pd.concat(all_players, ignore_index=True)\n",
    "\n",
    "    return combined_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process all data into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data processing...\n",
      "Found 6 player_results.csv files\n",
      "Found 86 contest-standings.csv files\n",
      "Found 86 players.csv files\n",
      "Data processing complete!\n",
      "Saved 931 player results\n",
      "Saved 1394152 contest entries\n",
      "Saved 10981 player selections\n",
      "Saved 16307 player projections\n"
     ]
    }
   ],
   "source": [
    "# Main processing script\n",
    "def process_all_data():\n",
    "    print(\"Starting data processing...\")\n",
    "    \n",
    "    # Load all datasets\n",
    "    player_results = load_player_results()\n",
    "    entries_df, player_records = load_contest_data()\n",
    "    player_projections = load_player_projections()\n",
    "    \n",
    "    # Save processed datasets\n",
    "    player_results.to_csv('processed_player_results.csv', index=False)\n",
    "    entries_df.to_csv('processed_contest_entries.csv', index=False)\n",
    "    player_records.to_csv('processed_player_selections.csv', index=False)\n",
    "    player_projections.to_csv('processed_player_projections.csv', index=False)\n",
    "\n",
    "    print(\"Data processing complete!\")\n",
    "    print(f\"Saved {len(player_results)} player results\")\n",
    "    print(f\"Saved {len(entries_df)} contest entries\")\n",
    "    print(f\"Saved {len(player_records)} player selections\")\n",
    "    print(f\"Saved {len(player_projections)} player projections\")\n",
    "    \n",
    "    return {\n",
    "        'player_results': player_results,\n",
    "        'contest_entries': entries_df,\n",
    "        'player_selections': player_records,\n",
    "        'player_projections': player_projections\n",
    "    }\n",
    "\n",
    "# Run the processing\n",
    "data = process_all_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
